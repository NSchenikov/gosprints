Спринт 4: Кеширование и метрики

Задача:

    Кеширование:
        Кэшировать популярные запросы к задачам (например, список новых задач) либо детальные данные по задаче.
        Можно хранить кеш в памяти (например, с помощью sync.Map) или в Redis — если хочется. Redis так же можно запустить докером.
        Настроить механизм протухания (TTL).
    Метрики:
        Собрать ключевые метрики: количество задач, среднее время обработки, число активных WebSocket-соединений.
        Реализовать эндпоинт /metrics для отдачи данных в JSON или формате, удобном для интеграции с Prometheus.

Спринт 5: Переход на gRPC и полнотекстовый поиск

Задача:
gRPC:
Создать сервис, который через gRPC позволяет выполнять некоторые операции над задачами (например, CreateTask, GetTask, ListTasks).
Оставить HTTP-сервис для внешнего REST API, но часть логики «внутри» перевести на gRPC. Можно, например, сделать микросервис «Task Service» на gRPC, а «API Gateway» на HTTP.
Полнотекстовый поиск:
Добавить поиск по задачам (по title и description) с использованием полнотекстового поиска PostgreSQL.
Создать эндпоинт (HTTP или gRPC) для поиска задач по ключевым словам.
Продумать индексы для ускорения поиска.

Цели:
Познакомиться с gRPC, .proto-файлами, генерацией кода, настройкой сервера и клиента.
Освоить полнотекстовый поиск в PostgreSQL и индексы.

        __________________________
        К третьему спринту:
        1) при повторном подключении user к ws что происходит со старым conn? Зависает, создавая утечку памяти или детектор дисконнекта в хэндлере может удалить новое подключение?
        Ответ: Клиент открывает новый WebSocket, NewWSHandler создаёт новый conn. AddClient заменяет старый conn на новый, но не закрывает его. Старый conn продолжает существовать в памяти, а хэндлер всё ещё висит в for { ReadMessage() }. Старая горутина не завершится. RemoveClient срабатывает только когда хэндлер получает ошибку
        upd: имеет ли смысл проверка oldConn != conn? В каких ситуациях это равенство может выполняться? В каких случаях проверка может быть не пройдена? Вопрос именно в том, в какои случае они могут быть равны.
        Ответ: в моем текущем коде oldConn != conn никогда не будет true. Проверка избыточна. Каждый новый вызов Upgrade создает новое подключение и оно физически не может совпадать со старым. Если для одного и того же conn будет вызываться AddClient то мы не закроем сами себя (без проверки закрыли бы только что активный conn). Если бы не было проверки, то AddClient можно было бы вызывать повторно, но подключение осталось бы прежним (не мой случай). Данная проверка может работать как страховка от self-close

        //добавить в схему queue, worker и notifier

        Проблема: в диспетчере каждые 5 секунд вызывался getByStatus - отсюда и misses.
        Диспетчер использовал тот же репозиторий, что и API. Каждый раз после чистки кэша, трех запросов в статистике получал 24 misses (30 секунд) из-за того, что диспетчер и воркеры создавали большую нагрузку. Разделил taskRepo на apiTaskRepo и workerTaskRepo (кэширующий и не кэширующий). WorkerTaskRepo для использования в воркерах и диспетчере, apiTaskRepo для использования в сервисах и кэшировании.
        Изменил addClient в hub. Сравнение сложных структур плохо тем, что сравниваются все поля в том числе и мьютекс, который сравниваться не должен - это приводит к неопределенному поведению. Может произойти ложное отрицание или ложное срабатываение.
        Добавил метрики по задачам, среднему времени обработки, и числу ws-соединений. Добавил /metrics и metrics/prometheus. После создания задачи tasks.created и tasks.completed меняется, но не меняются api-метрики (api.requests_total 0), cache.hits 0, при этом cache.sets 20.

разобраться с проблемой многочисленных missies. Достатать коммит где это не работало и разобраться.
почему не работают метрики - прологировать

!)ПО MISSES: GetByStatus не кэшировал пустые массивы. if tasks != nil (условие из getByStatus) никогда не выполнится для пустого массива потому что []models.Task{} != nil и len([]models.Task{}) == 0.
Пустой массив не кэшировался, отсюда каждый запрос диспетчера получал miss, поэтому БД грузилась каждые 5 секунд.
В GetByStatus удалил проверку if tasks != nil и теперь кэшируются любые результаты, включая пустые массивы.
Тем не менее разделение taskRepo на apiTaskRepo и workerTaskRepo имеет смысл, так как, когда API и диспетчер используют один кэш-репозиторий, API делает запрос /tasks → MISS → misses++, когда диспетчер делает запрос GetByStatus("pending") → MISS → misses++ - получаем лишний miss от диспетчера. Вывод: API делает частые повторяющиеся запросы и они отлично кэшируются, а воркеры делают редкие запросы для обработки задач и кэш им не нужен. apiTaskRepo имеет кэш со статистикой, а workerTaskRepo используется только диспетчером и воркерами и идет напрямую в БД без кэша.
!) ПО МЕТРИКАМ:

1. не работали метрики API и requests_total всегда был 0 из-за того, что middleware metrics.go пропускал запросы по эндпоинту /metrics; теперь middleware считает все запросы и ошибки
2. перестал работать websocket: требовал user_id. WS Handler ждал token, но wscat не может передавать заголовки. GetUserFromJWT искала токен только в заголовках. Расширил эту функцию для поддержки токена в query параметрах. То есть теперь токен можно передавать и в заголовках, и в URL.
3. Апгрейд WS падал с ошибкой response does not implement http.Hijacker. Middleware оборачивал ResponseWriter, а обертка не реализовывала интерфейс http.Hijacker, нужного для WS-соединений. Прологировал handler.go
4. Метрики кэша (json/prometheus по эндпоинту) кроме sets ничего не показывали: кэш использовался только на запись.
5. Неправильно работала логика инкремента метрик в обработчике задач - инкрементировался счетчик tasksCompleted. Теперь инкрементируется только при реальном завершении задачи.

!) ПО gRPC
создал proto-файлы и нужную архитектуру, подготовил структуру для gRPC-сервера и клиента, переписал handlers/tasks.go под gRPC (сохранил и прямой доступ через сервис)
Проблема: не установился protoc (скореее всего из-за проблем с совместимостью на старой macOS). Еще осталось сделать полнотекстовый поиск
